---
title: "Report"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introduction

In this group assignment for WQD7004: Programming for Data Science, the scope is to use R Programming to create both a classification model as well as a regression model using a single dataset for prediction purposes. After careful consideration and discussion, the chosen dataset is determined to be Student Data collected by Cortez and Silva (2008) in their research.
 
For context, the research conducted by Cortez and Silva (2008) was to assess the educational level of the Portuguese population from two different schools. This was presented as a concern as statistics have shown that Portugal has one of the highest failure rates in Europe despite their continuous improvements in the last decade. In 2006, the early school leaving rate in Portugal was 40% for those aged 18-24 years old, while the European Union average was only 15% (Eurostat, 2007). The two subjects most important are Mathematics and Portuguese as they are core classes that provide students with the fundamental information for success in other school subjects, such as Chemistry and History.
 
Modeling student performance has consequently always been an important tool for both educators, students, and researchers alike. It can help to further research in the domain of factors that affect student achievement. Thus, the researchers addressed the prediction of secondary student grades by using past school performance, demographic, social, and other school related data. They then tested out three different data mining goals (binary classification, five level classification, and regression) and four data mining methods (decision trees, random forests, neural networks, and support vector machines).
 
In concluding the study, the past researchers have noted that the best predictive accuracy of the final grade can be achieved if past performance grades are evaluated and that predictive performance decreases when each subsequent past performance is not used. However, the researchers have also postulated that the effects of other variables, such as number of school absences, parent’s job and education, and alcohol consumption, also influence the prediction of a student’s final grade, just not as much as past performance.

For this group assignment, the goal is to replicate the methodology in performing this predictive modeling study with specific alterations. The main deviation would be to only use the Portuguese language dataset, ignoring the Mathematics dataset given the present resource limitations of this group assignment.

### Problem Statement

Education is an important part of national society and plays a vital role in the growth and development of any country. Even more relevant as the country has one of the highest failure rates in Europe, the improvement of educational level is of great importance because of the progress of information technology, which has led to the exponential growth of commercial and organizational databases All of this data contains valuable information, such as trends and patterns, that can be used to improve decision making and optimize success education data mining is the application of data mining this is an emerging field of interdisciplinary research, the development of processing methods to explore the origins of data in the context of education Educational data mining is an emerging trend that aims to automatically explore unique data types from large repositories of education-related data, on the other hand, there is a wide range of skills among different educational practitioners, and the risk of neglecting details Therefore, the alternative is to use automated tools to analyze raw data and extract interesting high-level information for decision makers.

Education field for application of business intelligence provides the fertile soil, student performance simulation tool for educators and students is very important, it can help students and educators to a better understanding of this phenomenon and to help find problems so as to improve the existing situation Now now has existed for many similar theme research and has a higher accuracy For this project there are three different data mining objectives (binary classification five level classification and regression) and four data mining methods (decision tree random forest neural network and support vector machine) aimed at predicting student achievement and, if possible, identifying key variables that influence educational success/failure In the end, the prediction models developed this time should be no less accurate than the existing research and we should complete all relevant work by 13 weeks before the semester. In addition, the best models will be interpreted to identify the most relevant features.

### Research Questions

1. What are the factors that highly impact to the student performance?
2. How to design prediction models to predict student performance?
3. Which model is the best to predict student performance?

### Research Objectives

1. To identify the factors that highly correlated with the student performance
2. To create the regression and classification models to predict student performance
3. To evaluate the performance of the models

### Dataset

[Student Performance Data Set](https://archive.ics.uci.edu/ml/datasets/student+performance)

This dataset consists of student performance in secondary education of two Portuguese schools in year 2005 - 2006. It was collected through school reports and questionnaires. 

In this project, we are interested in the student performance in the Portuguese subject. It consists of 649 observations and 33 variables.

### Metadata

| Variable   | Description                                                  |
| ---------- | ------------------------------------------------------------ |
| school     | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira) |
| sex        | student's sex (binary: 'F' - female or 'M' - male)           |
| age        | student's age (numeric: from 15 to 22)                       |
| address    | student's home address type (binary: 'U' - urban or 'R' - rural) |
| famsize    | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3) |
| Pstatus    | parent's cohabitation status (binary: 'T' - living together or 'A' - apart) |
| Medu       | mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |
| Fedu       | father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |
| Mjob       | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| Fjob       | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other') |
| reason     | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other') |
| guardian   | student's guardian (nominal: 'mother', 'father' or 'other')  |
| traveltime | home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour) |
| studytime  | weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours) |
| failures   | number of past class failures (numeric: n if 1<=n<3, else 4) |
| schoolsup  | extra educational support (binary: yes or no)                |
| famsup     | family educational support (binary: yes or no)               |
| paid       | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no) |
| activities | extra-curricular activities (binary: yes or no)              |
| nursery    | attended nursery school (binary: yes or no)                  |
| higher     | wants to take higher education (binary: yes or no)           |
| internet   | Internet access at home (binary: yes or no)                  |
| romantic   | with a romantic relationship (binary: yes or no)             |
| famrel     | quality of family relationships (numeric: from 1 - very bad to 5 - excellent) |
| freetime   | free time after school (numeric: from 1 - very low to 5 - very high) |
| goout      | going out with friends (numeric: from 1 - very low to 5 - very high) |
| Dalc       | workday alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| Walc       | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high) |
| health     | current health status (numeric: from 1 - very bad to 5 - very good) |
| absences   | number of school absences (numeric: from 0 to 93)            |
| G1         | first period grade (numeric: from 0 to 20)                   |
| G2         | second period grade (numeric: from 0 to 20)                  |
| G3         | final grade (numeric: from 0 to 20, output target)           |

### References

1. Cortez, P., & Silva, A. M. G. (2008). Using data mining to predict secondary school student performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.
2. Eurostat. (2007). Early school-leavers. http://epp.eurostat.ec.europa.eu/.

### Imports

```{r}
library(dplyr)
library(ggplot2)
library(caret)
library(reshape)
```

```{r}
df <- read.csv("../data/student-por.csv", sep = ";", stringsAsFactors = TRUE)
head(df)
```

### Preprocessing

```{r}
str(df)
```

```{r}
summary(df)
```

Convert ordinal variables into ordered factors.

```{r}
df$famsize <- factor(df$famsize, ordered = TRUE, levels = c("LE3", "GT3"))
df$Medu <- factor(df$Medu, ordered = TRUE, levels = 0:4)
df$Fedu <- factor(df$Fedu, ordered = TRUE, levels = 0:4)
df$traveltime <- factor(df$traveltime, ordered = TRUE, levels = 1:4)
df$studytime <- factor(df$studytime, ordered = TRUE, levels = 1:4)
df$failures <- factor(df$failures, ordered = TRUE, levels = 0:4)
df$famrel <- factor(df$famrel, ordered = TRUE, levels = 1:5)
df$freetime <- factor(df$freetime, ordered = TRUE, levels = 1:5)
df$goout <- factor(df$goout, ordered = TRUE, levels = 1:5)
df$Dalc <- factor(df$Dalc, ordered = TRUE, levels = 1:5)
df$Walc <- factor(df$Walc, ordered = TRUE, levels = 1:5)
df$health <- factor(df$health, ordered = TRUE, levels = 1:5)
```

Create label from `G3`.

```{r}
df$result <- ifelse(df$G3 >= 10, "pass", "fail")
df$result <- as.factor(df$result)
```

### Descriptive Analysis

```{r}
str(df)
```

```{r}
summary(df)
```

### Exploratory Data Analysis

#### Univariate

```{r}
ggplot(df, aes(x = school)) + 
  geom_bar(fill='blue') +
  labs(x = "School",
       y = "No. of students",
       title = "1. Student's school")

ggplot(df, aes(x = sex)) + 
  geom_bar(fill='blue') +
  labs(x = "Sex",
       y = "No. of students",
       title = "2. Student's sex")

ggplot(df, aes(x = age)) + 
  geom_bar(fill='green', 
                 color = "black") +
  labs(x = "Age",
       y = "Frequency",
       title = "3. Student's age")

ggplot(df, aes(x = address)) + 
  geom_bar(fill='purple') +
  labs(x = "Address",
       y = "Frequency",
       title = "4. Student's home address type")

ggplot(df, aes(x = famsize)) + 
  geom_bar(fill='purple') +
  labs(x = "Family size",
       y = "Frequency",
       title = "5. Family size ")

ggplot(df, aes(x = Pstatus)) + 
  geom_bar(fill='purple') +
  labs(x = "Parent's Status",
       y = "Frequency",
       title = "6. Parent's cohabitation status ")

ggplot(df, aes(x = Medu)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Medu",
       y = "Frequency",
       title = "7. Mother's education level")

ggplot(df, aes(x = Fedu)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Fedu",
       y = "Frequency",
       title = "8. Father's education level")

ggplot(df, aes(x = Mjob)) + 
  geom_bar(fill='purple') +
  labs(x = "Mjob",
       y = "Frequency",
       title = "9. Mother's job")

ggplot(df, aes(x = Fjob)) + 
  geom_bar(fill='purple') +
  labs(x = "Fjob",
       y = "Frequency",
       title = "10. Father's job")

ggplot(df, aes(x = reason)) + 
  geom_bar(fill='purple') +
  labs(x = "Reason",
       y = "Frequency",
       title = "11. Reason for selecting school")

ggplot(df, aes(x = guardian)) + 
  geom_bar(fill='purple') +
  labs(x = "Guardian",
       y = "Frequency",
       title = "12. Student's guardian")

ggplot(df, aes(x = traveltime)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Traveltime",
       y = "Frequency",
       title = "13. Home to school travel time")

ggplot(df, aes(x = studytime)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Studytime",
       y = "Frequency",
       title = "14. Weekly study time")

ggplot(df, aes(x = failures)) +
  geom_bar(fill = "green", 
                 color = "black") + 
  labs(title="15. Number of past class failures")

ggplot(df, aes(x = schoolsup)) + 
  geom_bar(fill='blue') +
  labs(x = "Schoolsup",
       y = "Frequency",
       title = "16. Extra educational support")

ggplot(df, aes(x = famsup)) + 
  geom_bar(fill='blue') +
  labs(x = "Famsup",
       y = "Frequency",
       title = "17. Family educational support")

ggplot(df, aes(x = paid)) + 
  geom_bar(fill='blue') +
  labs(x = "Paid",
       y = "Frequency",
       title = "18. Extra paid Portuguese classes ")

ggplot(df, aes(x = activities)) + 
  geom_bar(fill='blue') +
  labs(x = "Activities",
       y = "Frequency",
       title = "19. Extra-curricular activities")

ggplot(df, aes(x = nursery)) + 
  geom_bar(fill='blue') +
  labs(x = "Nursery",
       y = "Frequency",
       title = "20. Attended nursery school")

ggplot(df, aes(x = higher)) + 
  geom_bar(fill='blue') +
  labs(x = "Higher",
       y = "Frequency",
       title = "21. Wants to take higher education")

ggplot(df, aes(x = internet)) + 
  geom_bar(fill='blue') +
  labs(x = "Internet",
       y = "Frequency",
       title = "22. Internet access at home")

ggplot(df, aes(x = romantic)) + 
  geom_bar(fill='blue') +
  labs(x = "Romantic",
       y = "Frequency",
       title = "23. In a romantic relationship")

ggplot(df, aes(x = famrel)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Famrel",
       y = "Frequency",
       title = "24. Quality of family relationship")

ggplot(df, aes(x = freetime)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Freetime",
       y = "Frequency",
       title = "25. Free time after school")

ggplot(df, aes(x = goout)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Goout",
       y = "Frequency",
       title = "26. Going out with friends")

ggplot(df, aes(x = Dalc)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Dalc",
       y = "Frequency",
       title = "27. Workday alcohol consumption")

ggplot(df, aes(x = Walc)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "Walc",
       y = "Frequency",
       title = "28. Weekend alcohol consumption")

ggplot(df, aes(x = health)) + 
  geom_bar(fill='white', 
                 color = "black") +
  labs(x = "health",
       y = "Frequency",
       title = "29. Current health status")

ggplot(df, aes(x = absences)) + 
  geom_bar(fill='green', 
                 color = "black")+
  labs(x = "Absences",
       y = "Frequency",
       title = "30. Number of school absences")

ggplot(df, aes(x = G1)) + 
  geom_bar(fill='pink', 
                 color = "black") +
  labs(x = "G1",
       y = "Frequency",
       title = "31. First period grade")

ggplot(df, aes(x = G2)) + 
  geom_bar(fill='pink', 
                 color = "black") +
  labs(x = "G2",
       y = "Frequency",
       title = "32. Second period grade")

ggplot(df, aes(x = G3)) + 
  geom_bar(fill='orange', 
                 color = "black") +
  labs(x = "G3",
       y = "Frequency",
       title = "33. Final grade-output target")

ggplot(df, aes(x = result)) + 
  geom_bar(fill='blue', 
                 color = "black") +
  labs(x = "Result",
       y = "Frequency",
       title = "34. Final grade-result")
```

#### Bivariate

General Function for Bar Graph Plotting

```{r}
# bar graph for bivariate analysis
Unstacked_bi_bar_graph <- function(`x.axis` = "", Result = ""){
  # Result represents dependent variable / usually being drawn in y-axis 
  # x-axis represent independent variable 
  # dodge is used to un-stake the bar graph
  
  # 1. counts (or sums of weights)
  bar <- ggplot(df, aes(`x.axis`))
  
  # 2. Number of tuples in each class
  graph_output <- bar + geom_bar(aes(fill = `Result`), position = 'dodge') + 
    labs(y = 'Frequency') 
  
  # 3. get data from the graph 
  graph_label <- layer_data(graph_output)
  
  # 4. Annotate value at respective bar
  graph_output <- graph_output + annotate(geom = "text", label = graph_label$count, 
                                          x = graph_label$x, y = 15)
  
  return(graph_output)
}
```


```{r}
bar.bivar = Unstacked_bi_bar_graph(df$school, df$result)
bar.bivar = bar.bivar + ggtitle(label = '1. School vs Final Grade Result') +
  labs(x = "Student's School") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$sex, df$result)
bar.bivar = bar.bivar + ggtitle(label = '2. Gender vs Final Grade Result') +
  labs(x = "Student's Sex") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$age, df$result)
bar.bivar = bar.bivar + ggtitle(label = '3. Age vs Final Grade Result') +
  labs(x = "Student's Age") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$address, df$result)
bar.bivar = bar.bivar + ggtitle(label = "4. Student's Home Address Type vs Final Grade Result") +
  labs(x = "Address Type") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$famsize, df$result)
bar.bivar = bar.bivar + ggtitle(label = "5. Student's Family Size vs Final Grade Result") +
  labs(x = "Family Size") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$Pstatus, df$result)
bar.bivar = bar.bivar + ggtitle(label = "6. Parent's Cohabitation Status vs Final Grade Result") +
  labs(x = "Parent's Cohabitation Status") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$Medu, df$result)
bar.bivar = bar.bivar + ggtitle(label = "7. Mother's Education vs Final Grade Result") +
  labs(x = "Mother's Education Level") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$Fedu, df$result)
bar.bivar = bar.bivar + ggtitle(label = "8. Father's Education vs Final Grade Result") +
  labs(x = "Father's Education Level") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$Mjob, df$result)
bar.bivar = bar.bivar + ggtitle(label = "9. Mother's Job vs Final Grade Result") +
  labs(x = "Mother's Job") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$Fjob, df$result)
bar.bivar = bar.bivar + ggtitle(label = "10. Father's Job vs Final Grade Result") +
  labs(x = "Father's Job") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$reason, df$result)
bar.bivar = bar.bivar + ggtitle(label = "11. Reason to Choose Selected School vs Final Grade Result") + labs(x = "Reason Types") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$guardian, df$result)
bar.bivar = bar.bivar + ggtitle(label = "12. Student's Guardian vs Final Grade Result") +
  labs(x = "Guardian") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$traveltime, df$result)
bar.bivar = bar.bivar + ggtitle(label = "13. Home to School Travel Time vs Final Grade Result") +
  labs(x = "Travel Time") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$studytime, df$result)
bar.bivar = bar.bivar + ggtitle(label = "14. Weekly Study Time vs Final Grade Result") +
  labs(x = "Weekly Study Time") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$failures, df$result)
bar.bivar = bar.bivar + ggtitle(label = "15. Number of Past Class Failures vs Final Grade Result") +
  labs(x = "Number of Past Class Failures") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$schoolsup, df$result)
bar.bivar = bar.bivar + ggtitle(label = "16. Extra Educational Support vs Final Grade Result") +
  labs(x = "Extra Educational Support") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$famsup, df$result)
bar.bivar = bar.bivar + ggtitle(label = "17. Family Educational Support vs Final Grade Result") +
  labs(x = "Family Educational Support") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$paid, df$result)
bar.bivar = bar.bivar + 
  ggtitle(label = "18. Extra Paid Classes for Portuguese Subject vs Final Grade Result") + 
  labs(x = "Joined Extra Paid Classes?") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$activities, df$result)
bar.bivar = bar.bivar + ggtitle(label = "19. Extra-Curricular Activities vs Final Grade Result") +
  labs(x = "Joined Extra-Curricular Activities?") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$activities, df$result)
bar.bivar = bar.bivar + ggtitle(label = "20. Extra-Curricular Activities vs Final Grade Result") +
  labs(x = "Joined Extra-Curricular Activities?") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$internet, df$result)
bar.bivar = bar.bivar + ggtitle(label = "21. Internet Access at Home vs Final Grade Result") +
  labs(x = "Internet Access at Home") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$romantic, df$result)
bar.bivar = bar.bivar + ggtitle(label = "22. With a Romantic Relationship vs Final Grade Result") +
  labs(x = "With a Romantic Relationship?") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$famrel, df$result)
bar.bivar = bar.bivar + ggtitle(label = "23. Quality of Family Relationships vs Final Grade Result") + labs(x = "Quality of Family Relationships") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$freetime, df$result)
bar.bivar = bar.bivar + ggtitle(label = "24. Free Time After School vs Final Grade Result") +
  labs(x = "Free Time After School") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$goout, df$result)
bar.bivar = bar.bivar + ggtitle(label = "25. Going Out with Friends vs Final Grade Result") +
  labs(x = "Going Out with Friends") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$Dalc, df$result)
bar.bivar = bar.bivar + ggtitle(label = "26. Workday Alcohol Consumption vs Final Grade Result") +
  labs(x = "Workday Alcohol Consumption") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$Walc, df$result)
bar.bivar = bar.bivar + ggtitle(label = "27. Weekend Alcohol Consumption vs Final Grade Result") +
  labs(x = "Weekend Alcohol Consumption") 
bar.bivar

bar.bivar = Unstacked_bi_bar_graph(df$health, df$result)
bar.bivar = bar.bivar + ggtitle(label = "28. Current Health Status vs Final Grade Result") +
  labs(x = "Current Health Status") 
bar.bivar

ggplot(df, aes(y = absences, x = result)) +
  geom_boxplot() + 
  ggtitle(label = "29. Number of School Absences vs Final Grade Result") + 
  labs(y = "Number of School Absences", x = "Result") + 
  scale_y_continuous(breaks=seq(0,36,by=2))

ggplot(df, aes(y = G1, x = result)) +
  geom_boxplot() + 
  labs(title = "30. First Period Grade vs Final Grade Result",
       y = "First Period Grade", 
       x = 'Result') + 
  scale_y_continuous(breaks=seq(0,22,by=2))

ggplot(df, aes(y = G2, x = result)) +
  geom_boxplot() + 
  labs(title = "31. Second Period Grade vs Final Grade Result",
       y = "Second Period Grade", 
       x = 'Result') +
  scale_y_continuous(breaks=seq(0,22,by=2))

```

#### Heat Map

#### 1. change processed dataset to matrix as 'heat_map_data'

```{r}
heat_map_data <- df %>% select(-1)
heat_map_data <- data.matrix(heat_map_data)
str(heat_map_data)
```

####2.caculate the correlation value for each attribute

```{r}
heat_map_data <- round(cor(heat_map_data, method = "pearson"),2)
head(heat_map_data)
```

####3.change the matrix student_pro from  short data to long data

```{r}
heat_map_data <- melt(heat_map_data)
head(heat_map_data)
```

####4. draw the Heat map

```{r}
heatmap <- ggplot(data = heat_map_data, aes(x=X1, y=X2, fill=value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low="red", high="darkblue")+
  theme(
 axis.text.x=element_text(angle=90, size=8),
 axis.title.x=element_text(angle=0, color='red'),
 axis.title.y=element_text(angle=360, color='blue')
 )+coord_equal()
heatmap
```

####5. only show the absolute correlation value of G3 with Descending order

```{r}
G3 <- subset(heat_map_data,X1=="G3")
G3[3] <- abs(G3[3])
G3 <- G3[order(G3[,3],decreasing = TRUE),]
G3
```

### Train-Test Split

Create train set and test set for regression and classification respectively.

#### Regression

```{r}
df_reg <- df

df_reg$result <- NULL

set.seed(42)

train_index_reg <- createDataPartition(
  df_reg$G3,
  p = 0.8,
  list = FALSE,
  times = 1
)

train_set_reg <- df_reg[train_index_reg, ]
test_set_reg <- df_reg[-train_index_reg, ]
```

#### Classification

```{r}
df_clf <- df

df_clf$G3 <- NULL

set.seed(42)

train_index_clf <- createDataPartition(
  df_clf$result,
  p = 0.8,
  list = FALSE,
  times = 1
)

train_set_clf <- df_clf[train_index_clf, ]
test_set_clf <- df_clf[-train_index_clf, ]
```

### Subsampling

Since we are dealing with imbalanced classes, we explore subsampling techniques for classification.

#### Original Sample

```{r}
table(train_set_clf$result)
```

#### Down-Sampling

```{r}
set.seed(42)

train_set_clf_down <- downSample(
  x = train_set_clf[, -ncol(train_set_clf)],
  y = train_set_clf$result,
  yname = "result"
)

table(train_set_clf_down$result)
```

#### Up-Sampling

```{r}
set.seed(42)

train_set_clf_up <- upSample(
  x = train_set_clf[, -ncol(train_set_clf)],
  y = train_set_clf$result,
  yname = "result"
)

table(train_set_clf_up$result)
```

### Modeling

Define repeated 10-fold cross validation.

```{r}
fit_control <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10
)
```

#### Regression

Helper function for regression models

```{r}
train_evaluate_reg <- function(method = "", data = train_set_reg, tuneGrid = NULL, tuneLength = NULL, name="") {
  set.seed(42)
  
  fit <- train(
    G3 ~ .,
    data = data,
    method = method,
    trControl = fit_control,
    preProcess = c("center", "scale"),
    tuneGrid = tuneGrid,
    tuneLength = tuneLength
  )
  print(fit)

  pred <- predict(fit, test_set_reg)
  result <- postResample(pred = pred, obs = test_set_reg$G3)
  
  metrics = data.frame(
        Model = name,
        RMSE = result[["RMSE"]],
        Rsquared = result[["Rsquared"]],
        MAE = result[["MAE"]]
      )

  return(
    list(
      model = fit,
      metrics = metrics
    )
  )
}
```

```{r}
get_best_result = function(caret_fit) {
  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result = caret_fit$results[best, ]
  rownames(best_result) = NULL
  best_result
}
```

#### 1. Decision Tree

CART

- method = 'rpart'
- Type: Regression, Classification
- Tuning parameters:
  - cp (Complexity Parameter)
- Required packages: rpart
- A model-specific variable importance metric is available.

Training model with auto tuning:

```{r}
dt_reg <- train_evaluate_reg("rpart", name = "DT", tuneLength = 10)

```

Best parameters from tuning:

```{r}
get_best_result(dt_reg$model)
``` 

Plot the trained model:

```{r}
plot(dt_reg$model)
```

- Value 0.005577788 is the optimal value for complexity parameter.

Evaluation of model:

```{r}
dt_reg$metrics
```

#### 2. Random Forest

Random Forest

- method = 'ranger'
- Type: Classification, Regression
- Tuning parameters:
  - mtry (#Randomly Selected Predictors) (Number of variables randomly sampled as candidates at each split.)
  - splitrule (Splitting Rule)
  - min.node.size (Minimal Node Size)
- Required packages: e1071, ranger, dplyr
- A model-specific variable importance metric is available.

Training model with auto tuning:

```{r}
rf_reg <- train_evaluate_reg("ranger", name = "RF", tuneLength = 10)

```

Best parameters from tuning:

```{r}
get_best_result(rf_reg$model)
``` 

Plot the trained model:

```{r}
plot(rf_reg$model)
```

- For splitrule (splitting rule) = variance, mtry = 48 is already the optimal value.
- For splitrule (splitting rule) = extratrees, mtry = 64. Can try to tune with mtry between 64 and 72 (max mtry = 72).
- Tuning parameter 'min.node.size' was held constant at a value of 5, can try to tune with other values.

Training model with manual tuning:

- splitrule = variance or extratrees
- mtry between 48 to 72
- min.node.size between 1 to 10

```{r}
tuneGrid_rf_reg <- expand.grid(
  splitrule = c("variance","extratrees"),
  mtry = seq(48,72,by=2),
  min.node.size = seq(1,10)
)

rf_reg_manual_tune <- train_evaluate_reg("ranger", name = "RF", tuneGrid = tuneGrid_rf_reg)
```

Best parameters from tuning:

```{r}
get_best_result(rf_reg_manual_tune$model)
``` 

Plot the trained model:

```{r}
plot(rf_reg_manual_tune$model)
```

Optimal value for each parameters:

- mtry = 72
- splitrule = extratrees
- min.node.size = 9

Evaluation of model:

```{r}
rf_reg_manual_tune$metrics
``` 

#### 3. SVM with Polynomial Kernel

Support Vector Machines with Polynomial Kernel

- method = 'svmPoly'
- Type: Regression, Classification
- Tuning parameters:
  - degree (Polynomial Degree)
  - scale (Scale)
  - C (Cost)
- Required packages: kernlab

Training model with auto tuning:

- We have tried with tuneLength of 10, unfortunately it took too much of time to finish, thus we have decided to go with tuneLength of 5 in SVM.

```{r}
svm_reg <- train_evaluate_reg("svmPoly", name = "SVM", tuneLength = 5)

```

Best parameters from tuning:

```{r}
get_best_result(svm_reg$model)
``` 

Plot the trained model:

```{r}
plot(svm_reg$model)
```

- The parameters degree (Polynomial Degree) = 1, scale = 10, and C (Cost) = 0.25 reached their optimal value.

Evaluation of model:

```{r}
svm_reg$metrics
``` 

#### 4. XGBoost

- method = ‘xgbLinear’
- Type: Regression, Classification
- Tuning parameters:
  - nrounds (#Boosting Iterations)
  - lambda (L2 Regularization)
  - alpha (L1 Regularization)
  - eta (Learning Rate)
- Required packages: xgboost
- A model-specific variable importance metric is available.

Training model with auto tuning:

```{r}
xgb_reg <- train_evaluate_reg("xgbLinear", name = "XGB", tuneLength = 3)
```

Best parameters from tuning:

```{r}
get_best_result(xgb_reg$model)
``` 

Plot the trained model:

```{r}
plot(xgb_reg$model)
```

Training model with manual tuning:

```{r}
tuneGrid_xgb_reg <- expand.grid(
  eta = 0.3,
  lambda = 0.1,
  alpha = c(0.001, 0.01, 0.1),
  nrounds = seq(10, 70, 10)
)

xgb_reg_manual_tune <- train_evaluate_reg("xgbLinear", name = "XGB", tuneGrid = tuneGrid_xgb_reg)
```

Best parameters from tuning:

```{r}
get_best_result(xgb_reg_manual_tune$model)
``` 

Plot the trained model:

```{r}
plot(xgb_reg_manual_tune$model)
```

Evaluation of model:

```{r}
xgb_reg_manual_tune$metrics
``` 

#### 5. Linear Regression with Regularization

- method = ‘glmnet’
- Type: Regression, Classification
- Tuning parameters:
  - alpha (Mixing Percentage)
  - lambda (Regularization Parameter)
- Required packages: glmnet, Matrix
- A model-specific variable importance metric is available.

Training model with auto tuning:

```{r}
lr_reg <- train_evaluate_reg("glmnet", name = "Linear Regression", tuneLength = 10)

```

Best parameters from tuning:

```{r}
get_best_result(lr_reg$model)
``` 

Plot the trained model:

```{r}
plot(lr_reg$model)
```

- The parameter alpha (Mixing Percentage) = 1 is the optimal value while there's possibility to get better result with lambda (Regularization Parameter) < 0.2110029.

Training model with manual tuning:

- alpha = 1
- lambda between 0.001 to 0.300

```{r}
tuneGrid_lr_reg <- expand.grid(
  alpha = c(1),
  lambda = seq(0.00,0.30,by=0.05)
)

lr_reg_manual_tune <- train_evaluate_reg("glmnet", name = "Linear Regression", tuneGrid = tuneGrid_lr_reg)
```

Best parameters from tuning:

```{r}
get_best_result(lr_reg_manual_tune$model)
``` 

Plot the trained model:

```{r}
plot(lr_reg_manual_tune$model)
```

- The parameter alpha (Mixing Percentage) = 1 and lambda (Regularization Parameter) = 0.15 reached their optimal value.

Evaluation of model:

```{r}
lr_reg_manual_tune$metrics
```

#### Classification

Define a helper function to train model.

```{r}
train_model_clf <- function(method = "",
                        data = train_set_clf,
                        tuneGrid = NULL,
                        tuneLength = 3) {
  set.seed(42)

  fit <- train(
    result ~ .,
    data = data,
    method = method,
    trControl = fit_control,
    preProcess = c("center", "scale"),
    tuneGrid = tuneGrid,
    tuneLength = tuneLength
  )

  print(fit)
  
  return(fit)
}
```

Define a helper function to evaluate model.

```{r}
evaluate_model_clf <- function(model = NULL, alias = "", family = "") {
  pred <- predict(model, test_set_clf)

  cm <- confusionMatrix(pred, test_set_clf$result, mode = "prec_recall")
  print(cm)

  precision_score <- precision(pred, test_set_clf$result)
  recall_score <- recall(pred, test_set_clf$result)
  f1_score <- F_meas(pred, test_set_clf$result)

  return(data.frame(
    Model = alias,
    Family = ifelse(family == "", alias, family),
    Accuracy = round(cm$overall[["Accuracy"]], 3),
    Precision = round(precision_score, 3),
    Recall = round(recall_score, 3),
    F1 = round(f1_score, 3)
  ))
}
```

#### 1. Decision Tree

- method = ‘rpart2’
- Type: Regression, Classification
- Tuning parameters:
  - maxdepth (Max Tree Depth)
- Required packages: rpart
- A model-specific variable importance metric is available.

##### Original Train Set

```{r}
dt_clf <- train_model_clf("rpart2")
```

```{r}
plot(dt_clf)
```

No further tuning required.

```{r}
dt_metrics_clf <- evaluate_model_clf(dt_clf, "DT")
```

##### Down-Sampled Train Set

```{r}
down_dt_clf <- train_model_clf("rpart2", train_set_clf_down)
```

```{r}
plot(down_dt_clf)
```

No further tuning required.

```{r}
down_dt_metrics_clf <- evaluate_model_clf(down_dt_clf, "DT")
```

##### Up-Sampled Train Set

```{r}
up_dt_clf <- train_model_clf("rpart2", train_set_clf_up)
```

```{r}
plot(up_dt_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_dt_clf <- train_model_clf("rpart2", train_set_clf_up, tuneLength = 10)
```

```{r}
plot(up_dt_clf)
```

Tuning done.

```{r}
up_dt_metrics_clf <- evaluate_model_clf(up_dt_clf, "DT")
```

#### 2. Random Forest

- method = ‘ranger’
- Type: Regression, Classification
- Tuning parameters:
  - mtry (#Randomly Selected Predictors)
  - splitrule (Splitting Rule)
  - min.node.size (Minimal Node Size)
- Required packages: e1071, ranger, dplyr
- A model-specific variable importance metric is available.

##### Original Train Set

```{r}
rf_clf <- train_model_clf("ranger")
```

```{r}
plot(rf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
rf_clf <- train_model_clf("ranger", tuneLength = 7)
```

```{r}
plot(rf_clf)
```

Tuning done.

```{r}
rf_metrics_clf <- evaluate_model_clf(rf_clf, "RF")
```

##### Down-Sampled Train Set

```{r}
down_rf_clf <- train_model_clf("ranger", train_set_clf_down)
```

```{r}
plot(down_rf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
down_rf_clf <- train_model_clf("ranger", train_set_clf_down, tuneLength = 7)
```

```{r}
plot(down_rf_clf)
```

Tuning done.

```{r}
down_rf_metrics_clf <- evaluate_model_clf(down_rf_clf, "RF")
```

##### Up-Sampled Train Set

```{r}
up_rf_clf <- train_model_clf("ranger", train_set_clf_up)
```

```{r}
plot(up_rf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_rf_clf <- train_model_clf("ranger", train_set_clf_up, tuneLength = 7)
```

```{r}
plot(up_rf_clf)
```

Tuning done.

```{r}
up_rf_metrics_clf <- evaluate_model_clf(up_rf_clf, "RF")
```

#### 3. SVM with Polynomial Kernel

- method = ‘svmPoly’
- Type: Regression, Classification
- Tuning parameters:
  - degree (Polynomial Degree)
  - scale (Scale)
  - C (Cost)
- Required packages: kernlab

##### Original Train Set

```{r}
svm_poly_clf <- train_model_clf("svmPoly")
```

```{r}
plot(svm_poly_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
svm_poly_tuneGrid_clf <- expand.grid(
  degree = 1,
  scale = c(0.01, 0.1),
  C = seq(0.1, 1.5, 0.05)
)

svm_poly_clf <- train_model_clf("svmPoly", tuneGrid = svm_poly_tuneGrid_clf)
```

```{r}
plot(svm_poly_clf)
```

Tuning done.

```{r}
svm_poly_metrics_clf <- evaluate_model_clf(svm_poly_clf, "SVM - Poly", "SVM")
```

##### Down-Sampled Train Set

```{r}
down_svm_poly_clf <- train_model_clf("svmPoly", train_set_clf_down)
```

```{r}
plot(down_svm_poly_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_svm_poly_tuneGrid_clf <- expand.grid(
  degree = 3,
  scale = 0.01,
  C = seq(0.25, 1, 0.05)
)

down_svm_poly_clf <- train_model_clf(
  "svmPoly",
  train_set_clf_down,
  tuneGrid = down_svm_poly_tuneGrid_clf
)
```

```{r}
plot(down_svm_poly_clf)
```

Tuning done.

```{r}
down_svm_poly_metrics_clf <- evaluate_model_clf(
  down_svm_poly_clf, 
  "SVM - Poly", 
  "SVM"
)
```

##### Up-Sampled Train Set

```{r}
up_svm_poly_clf <- train_model_clf("svmPoly", train_set_clf_up)
```

```{r}
plot(up_svm_poly_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
up_svm_poly_tuneGrid_clf <- expand.grid(
  degree = 3,
  scale = 0.1,
  C = seq(0.05, 0.25, 0.05)
)

up_svm_poly_clf <- train_model_clf(
  "svmPoly",
  train_set_clf_up,
  tuneGrid = up_svm_poly_tuneGrid_clf
)
```

```{r}
plot(up_svm_poly_clf)
```

Tuning done.

```{r}
up_svm_poly_metrics_clf <- evaluate_model_clf(
  up_svm_poly_clf, 
  "SVM - Poly", "SVM"
)
```

#### 4. K-Nearest Neighbors

- method = ‘knn’
- Type: Classification, Regression
- Tuning parameters:
  - k (#Neighbors)

##### Original Train Set

```{r}
knn_clf <- train_model_clf("knn")
```

```{r}
plot(knn_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
knn_clf <- train_model_clf("knn", tuneGrid = expand.grid(k = c(3, 5, 7, 11) ))
```

```{r}
plot(knn_clf)
```

No further tuning necessary. 

```{r}
knn_metrics_clf <- evaluate_model_clf(knn_clf, "KNN")
```

##### Down-Sampled Train Set

```{r}
down_knn_clf <- train_model_clf("knn", train_set_clf_down)
```

```{r}
plot(down_knn_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_knn_clf <- train_model_clf(
  "knn", 
  train_set_clf_down, 
  tuneGrid = expand.grid(k = c(9, 11, 13,15) )
)
```

```{r}
plot(down_knn_clf)
```

No further tuning required.

```{r}
down_knn_metrics_clf <- evaluate_model_clf(down_knn_clf, "KNN")
```

##### Up-Sampled Train Set

```{r}
up_knn_clf <- train_model_clf("knn", train_set_clf_up)
```

```{r}
plot(up_knn_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
up_knn_clf <- train_model_clf(
  "knn", 
  train_set_clf_up, 
  tuneGrid = expand.grid(k = c(1,3,5) )
)
```

```{r}
plot(up_knn_clf)
```

Tuning done.

```{r}
up_knn_metrics_clf <- evaluate_model_clf(up_knn_clf, "KNN")
```

#### 5. Logistic Regression

- method = ‘glmnet’
- Type: Regression, Classification
- Tuning parameters:
  - alpha (Mixing Percentage)
  - lambda (Regularization Parameter)
- Required packages: glmnet, Matrix
- A model-specific variable importance metric is available.

##### Original Train Set

```{r}
lr_clf <- train_model_clf("glmnet")
```

```{r}
plot(lr_clf)
```

Check for tuning using `tuneLength`.

```{r}
lr_clf <- train_model_clf("glmnet", tuneLength = 10)
```

```{r}
plot(lr_clf)
```

No further tuning necessary. 

```{r}
lr_metrics_clf <- evaluate_model_clf(lr_clf, "Logistic Regression")
```

##### Down-Sampled Train Set

```{r}
down_lr_clf <- train_model_clf("glmnet", train_set_clf_down)
```

```{r}
plot(down_lr_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
down_lr_clf <- train_model_clf("glmnet", train_set_clf_down, tuneLength = 10)
```

```{r}
plot(down_lr_clf)
```

No further tuning required.

```{r}
down_lr_metrics_clf <- evaluate_model_clf(down_lr_clf, "Logistic Regression")
```

##### Up-Sampled Train Set

```{r}
up_lr_clf <- train_model_clf("glmnet", train_set_clf_up)
```

```{r}
plot(up_lr_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_lr_clf <- train_model_clf("glmnet", train_set_clf_up, tuneLength = 10)
```

```{r}
plot(up_lr_clf)
```

Tuning done.

```{r}
up_lr_metrics_clf <- evaluate_model_clf(up_lr_clf, "Logistic Regression")
```

### Evaluation

#### Regression

##### By RMSE

```{r}
df_eval_reg <- rbind(
  dt_reg$metrics, 
  rf_reg_manual_tune$metrics, 
  svm_reg$metrics,
  xgb_reg_manual_tune$metrics,
  lr_reg_manual_tune$metrics
)

df_eval_reg <- df_eval_reg[order(df_eval_reg$RMSE),]
row.names(df_eval_reg) <- NULL
df_eval_reg

```

```{r}
df_eval_reg["RMSE"] = round(df_eval_reg["RMSE"],4)
df_eval_reg %>%
  ggplot(aes(x = reorder(Model, RMSE), y = RMSE, fill = Model)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = RMSE), vjust=-0.5) +
  ggtitle("RMSE by Model") +
  xlab("Model") +
  ylim(0,1.5) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

#### Classification

Define a function to plot accuracy.

```{r}
show_accuracy <- function(df) {
  df_accuracy <- df %>%
    group_by(Family) %>%
    slice(which.max(Accuracy)) %>%
    arrange(desc(Accuracy)) %>%
    select(-1)

  print(df_accuracy)
  
  plot_accuracy <- df_accuracy %>%
    ggplot(aes(x = reorder(Family, -Accuracy), y = Accuracy, fill = Family)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = Accuracy), vjust=-0.5) +
    ggtitle("Accuracy by Model") +
    xlab("Model") +
    ylim(0, 1) +
    labs(fill = "Model") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
  print(plot_accuracy)
}
```

Define a function to plot F1 score.

```{r}
show_f1 <- function(df) {
  df_f1 <- df %>%
    group_by(Family) %>%
    slice(which.max(F1)) %>%
    arrange(desc(F1)) %>%
    select(-1)

  print(df_f1)
  
  plot_f1 <- df_f1 %>%
    ggplot(aes(x = reorder(Family, -F1), y = F1, fill = Family)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = F1), vjust=-0.5) +
    ggtitle("F1 Score by Model") +
    xlab("Model") +
    ylab("F1 Score") +
    ylim(0, 1) +
    labs(fill = "Model") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
  print(plot_f1)
}
```

#### 1. Original Train Set

```{r}
df_eval_clf <- rbind(
  dt_metrics_clf,
  rf_metrics_clf,
  svm_poly_metrics_clf,
  knn_metrics_clf,
  lr_metrics_clf
)

df_eval_clf
```

##### By Accuracy

```{r}
show_accuracy(df_eval_clf)
```

##### By F1 Score

```{r}
show_f1(df_eval_clf)
```

#### 2. Down-Sampled Train Set

```{r}
down_df_eval_clf <- rbind(
  down_dt_metrics_clf,
  down_rf_metrics_clf,
  down_svm_poly_metrics_clf,
  down_knn_metrics_clf,
  down_lr_metrics_clf
)

down_df_eval_clf
```

##### By Accuracy

```{r}
show_accuracy(down_df_eval_clf)
```

##### By F1 Score

```{r}
show_f1(down_df_eval_clf)
```

#### 3. Up-Sampled Train Set

```{r}
up_df_eval_clf <- rbind(
  up_dt_metrics_clf,
  up_rf_metrics_clf,
  up_svm_poly_metrics_clf,
  up_knn_metrics_clf,
  up_lr_metrics_clf
)

up_df_eval_clf
```

##### By Accuracy

```{r}
show_accuracy(up_df_eval_clf)
```

##### By F1 Score

```{r}
show_f1(up_df_eval_clf)
```

### Conclusion

In this study, we develop and evaluate the performance of different regression models and binary classification models to predict student performance in secondary education of two Portugese schools. G3, the final grade result is the target attribute in regression models while in binary classification models, the target attribute "result" is created by segregating the G3 result into binary labels "pass" and "fail". All the models are trained with hyperparameter tuning to optimize their performance.

From the EDA result, we discovered that the attributes G1 and G2 are highly correlated to the target attribute G3. It shown that students that achieved higher G1 and G2 results are most likely to achieve higher G3 result.

We aim to achieve better prediction result compared to previous study by Cortez and Silva (2008) where the study achieved RMSE of 1.32 and accuracy of 93% from their best regression model and binary classification model respectively. The research outcome shown that our best models outperformed the result from previous study with RMSE of 1.11 from regression model using random forest and accuracy of 93.8% from binary classification model using decision tree.

In addition, we noticed the issue of imbalanced data with 440 pass label and 80 fail label in training dataset to address classification problem. Thus we have also trained the binary classification models using down-sampling and up-sampling data. We have compared the result of classification models using original sample data, down-sampling data, and up-sampling data. The comparison shown that the models using original dataset outperformed the other two datasets.

In future work, G1 and G2 attributes can be removed from the features so that we can further study the impact of other attributes to student performance to address a more specific problem. For instance, future work can be conducted to study whether family background affects student's academic result by predicting student performance with their family ecological factors.
