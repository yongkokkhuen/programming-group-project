---
title: "Classification"
output: html_notebook
---

### Best Result From Previous Study

93% PCC with Decision Tree - [Reference](http://www3.dsi.uminho.pt/pcortez/student.pdf)

### Imports

```{r}
library(dplyr)
library(ggplot2)
library(caret)
```

### Preparation

```{r}
df <- read.csv("../data/student-por_v3.csv", stringsAsFactors = TRUE)
head(df)
```

```{r}
str(df)
```

```{r}
summary(df)
```

Convert ordinal variables into ordered factors.

```{r}
df$famsize <- factor(df$famsize, ordered = TRUE, levels = c("LE3", "GT3"))
df$Medu <- factor(df$Medu, ordered = TRUE, levels = 0:4)
df$Fedu <- factor(df$Fedu, ordered = TRUE, levels = 0:4)
df$traveltime <- factor(df$traveltime, ordered = TRUE, levels = 1:4)
df$studytime <- factor(df$studytime, ordered = TRUE, levels = 1:4)
df$failures <- factor(df$failures, ordered = TRUE, levels = 0:4)
df$famrel <- factor(df$famrel, ordered = TRUE, levels = 1:5)
df$freetime <- factor(df$freetime, ordered = TRUE, levels = 1:5)
df$goout <- factor(df$goout, ordered = TRUE, levels = 1:5)
df$Dalc <- factor(df$Dalc, ordered = TRUE, levels = 1:5)
df$Walc <- factor(df$Walc, ordered = TRUE, levels = 1:5)
df$health <- factor(df$health, ordered = TRUE, levels = 1:5)
```

Drop `G3` column as `G3` will be used for regression.

```{r}
df$G3 <- NULL
```

```{r}
str(df)
```

```{r}
summary(df)
```

### Train-Test Split

```{r}
set.seed(42)

train_index <- createDataPartition(
  df$result,
  p = 0.8,
  list = FALSE,
  times = 1
)

train_set <- df[train_index, ]
test_set <- df[-train_index, ]
```

```{r}
nrow(train_set)
```

```{r}
nrow(test_set)
```

### Subsampling

Check original classes.

```{r}
table(train_set$result)
```

Create sample using down-sampling.

```{r}
set.seed(42)

down_train_set <- downSample(
  x = train_set[, -ncol(train_set)],
  y = train_set$result,
  yname = "result"
)

table(down_train_set$result)
```

Create sample using up-sampling.

```{r}
set.seed(42)

up_train_set <- upSample(
  x = train_set[, -ncol(train_set)],
  y = train_set$result,
  yname = "result"
)

table(up_train_set$result)
```

### Modeling

Define repeated 10-fold cross validation.

```{r}
fit_control <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10
)
```

Define a helper function to train model.

```{r}
train_model <- function(method = "",
                        data = train_set,
                        tuneGrid = NULL,
                        tuneLength = 3) {
  set.seed(42)

  fit <- train(
    result ~ .,
    data = data,
    method = method,
    trControl = fit_control,
    preProcess = c("center", "scale"),
    tuneGrid = tuneGrid,
    tuneLength = tuneLength
  )

  print(fit)
  
  return(fit)
}
```

Define a helper function to evaluate model.

```{r}
evaluate_model <- function(model = NULL, alias = "", family = "") {
  pred <- predict(model, test_set)

  cm <- confusionMatrix(pred, test_set$result, mode = "prec_recall")
  print(cm)

  precision_score <- precision(pred, test_set$result)
  recall_score <- recall(pred, test_set$result)
  f1_score <- F_meas(pred, test_set$result)

  return(data.frame(
    Model = alias,
    Family = ifelse(family == "", alias, family),
    Accuracy = round(cm$overall[["Accuracy"]], 3),
    Precision = round(precision_score, 3),
    Recall = round(recall_score, 3),
    F1 = round(f1_score, 3)
  ))
}
```

#### Decision Tree

##### Original Train Set

```{r}
dt_clf <- train_model("rpart2")
```

```{r}
plot(dt_clf)
```

No further tuning required.

```{r}
dt_metrics <- evaluate_model(dt_clf, "DT")
```

##### Down-Sampled Train Set

```{r}
down_dt_clf <- train_model("rpart2", down_train_set)
```

```{r}
plot(down_dt_clf)
```

No further tuning required.

```{r}
down_dt_metrics <- evaluate_model(down_dt_clf, "DT")
```

##### Up-Sampled Train Set

```{r}
up_dt_clf <- train_model("rpart2", up_train_set)
```

```{r}
plot(up_dt_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_dt_clf <- train_model("rpart2", up_train_set, tuneLength = 10)
```

```{r}
plot(up_dt_clf)
```

Tuning done.

```{r}
up_dt_metrics <- evaluate_model(up_dt_clf, "DT")
```

#### Random Forest

##### Original Train Set

```{r}
rf_clf <- train_model("ranger")
```

```{r}
plot(rf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
rf_clf <- train_model("ranger", tuneLength = 7)
```

```{r}
plot(rf_clf)
```

Tuning done.

```{r}
rf_metrics <- evaluate_model(rf_clf, "RF")
```

##### Down-Sampled Train Set

```{r}
down_rf_clf <- train_model("ranger", down_train_set)
```

```{r}
plot(down_rf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
down_rf_clf <- train_model("ranger", down_train_set, tuneLength = 7)
```

```{r}
plot(down_rf_clf)
```

Tuning done.

```{r}
down_rf_metrics <- evaluate_model(down_rf_clf, "RF")
```

##### Up-Sampled Train Set

```{r}
up_rf_clf <- train_model("ranger", up_train_set)
```

```{r}
plot(up_rf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_rf_clf <- train_model("ranger", up_train_set, tuneLength = 7)
```

```{r}
plot(up_rf_clf)
```

Tuning done.

```{r}
up_rf_metrics <- evaluate_model(up_rf_clf, "RF")
```

#### Support Vector Machine (Linear Kernel)

##### Original Train Set

```{r}
svm_lin_clf <- train_model("svmLinear2")
```

```{r}
plot(svm_lin_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
svm_lin_tuneGrid <- expand.grid(cost = seq(0.05, 0.5, 0.05))

svm_lin_clf <- train_model("svmLinear2", tuneGrid = svm_lin_tuneGrid)
```

```{r}
plot(svm_lin_clf)
```

Tuning done.

```{r}
svm_lin_metrics <- evaluate_model(svm_lin_clf, "SVM - Linear", "SVM")
```

##### Down-Sampled Train Set

```{r}
down_svm_lin_clf <- train_model("svmLinear2", down_train_set)
```

```{r}
plot(down_svm_lin_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_svm_lin_tuneGrid <- expand.grid(cost = seq(0.05, 0.5, 0.05))

down_svm_lin_clf <- train_model(
  "svmLinear2",
  down_train_set,
  tuneGrid = down_svm_lin_tuneGrid
)
```

```{r}
plot(down_svm_lin_clf)
```

Tuning done.

```{r}
down_svm_lin_metrics <- evaluate_model(down_svm_lin_clf, "SVM - Linear", "SVM")
```

##### Up-Sampled Train Set

```{r}
up_svm_lin_clf <- train_model("svmLinear2", up_train_set)
```

```{r}
plot(up_svm_lin_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_svm_lin_clf <- train_model("svmLinear2", up_train_set, tuneLength = 10)
```

```{r}
plot(up_svm_lin_clf)
```

Tuning done.

```{r}
up_svm_lin_metrics <- evaluate_model(up_svm_lin_clf, "SVM - Linear", "SVM")
```

#### Support Vector Machine (Polynomial Kernel)

##### Original Train Set

```{r}
svm_poly_clf <- train_model("svmPoly")
```

```{r}
plot(svm_poly_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
svm_poly_tuneGrid <- expand.grid(
  degree = 1,
  scale = c(0.01, 0.1),
  C = seq(0.1, 1.5, 0.05)
)

svm_poly_clf <- train_model("svmPoly", tuneGrid = svm_poly_tuneGrid)
```

```{r}
plot(svm_poly_clf)
```

Tuning done.

```{r}
svm_poly_metrics <- evaluate_model(svm_poly_clf, "SVM - Poly", "SVM")
```

##### Down-Sampled Train Set

```{r}
down_svm_poly_clf <- train_model("svmPoly", down_train_set)
```

```{r}
plot(down_svm_poly_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_svm_poly_tuneGrid <- expand.grid(
  degree = 3,
  scale = 0.01,
  C = seq(0.25, 1, 0.05)
)

down_svm_poly_clf <- train_model(
  "svmPoly",
  down_train_set,
  tuneGrid = down_svm_poly_tuneGrid
)
```

```{r}
plot(down_svm_poly_clf)
```

Tuning done.

```{r}
down_svm_poly_metrics <- evaluate_model(down_svm_poly_clf, "SVM - Poly", "SVM")
```

##### Up-Sampled Train Set

```{r}
up_svm_poly_clf <- train_model("svmPoly", up_train_set)
```

```{r}
plot(up_svm_poly_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
up_svm_poly_tuneGrid <- expand.grid(
  degree = 3,
  scale = 0.1,
  C = seq(0.05, 0.25, 0.05)
)

up_svm_poly_clf <- train_model(
  "svmPoly",
  up_train_set,
  tuneGrid = up_svm_poly_tuneGrid
)
```

```{r}
plot(up_svm_poly_clf)
```

Tuning done.

```{r}
up_svm_poly_metrics <- evaluate_model(up_svm_poly_clf, "SVM - Poly", "SVM")
```

#### Support Vector Machine (Radial Basis Function Kernel)

##### Original Train Set

```{r}
svm_rbf_clf <- train_model("svmRadial")
```

```{r}
plot(svm_rbf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
svm_rbf_clf <- train_model("svmRadial", tuneLength = 7)
```

```{r}
plot(svm_rbf_clf)
```

Tuning done.

```{r}
svm_rbf_metrics <- evaluate_model(svm_rbf_clf, "SVM - RBF", "SVM")
```

##### Down-Sampled Train Set

```{r}
down_svm_rbf_clf <- train_model("svmRadial", down_train_set)
```

```{r}
plot(down_svm_rbf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
down_svm_rbf_clf <- train_model("svmRadial", down_train_set, tuneLength = 7)
```

```{r}
plot(down_svm_rbf_clf)
```

Tuning done.

```{r}
down_svm_rbf_metrics <- evaluate_model(down_svm_rbf_clf, "SVM - RBF", "SVM")
```

##### Up-Sampled Train Set

```{r}
up_svm_rbf_clf <- train_model("svmRadial", up_train_set)
```

```{r}
plot(up_svm_rbf_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_svm_rbf_clf <- train_model("svmRadial", up_train_set, tuneLength = 10)
```

```{r}
plot(up_svm_rbf_clf)
```

Tuning done.

```{r}
up_svm_rbf_metrics <- evaluate_model(up_svm_rbf_clf, "SVM - RBF", "SVM")
```

#### Naive Bayes

##### Original Train Set

```{r}
nb_clf <- train_model("naive_bayes")
```

```{r}
plot(nb_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
nb_tuneGrid <- expand.grid(
  adjust = 1,
  usekernel = FALSE,
  laplace = seq(0, 1, 0.1)
)

nb_clf <- train_model("naive_bayes", tuneGrid = nb_tuneGrid)
```

```{r}
plot(nb_clf)
```

Tuning done.

```{r}
nb_metrics <- evaluate_model(nb_clf, "NB")
```

##### Down-Sampled Train Set

```{r}
down_nb_clf <- train_model("naive_bayes", down_train_set)
```

```{r}
plot(down_nb_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_nb_tuneGrid <- expand.grid(
  adjust = 1,
  usekernel = FALSE,
  laplace = seq(0, 1, 0.1)
)

down_nb_clf <- train_model(
  "naive_bayes",
  down_train_set,
  tuneGrid = down_nb_tuneGrid
)
```

```{r}
plot(down_nb_clf)
```

Tuning done.

```{r}
down_nb_metrics <- evaluate_model(down_nb_clf, "NB")
```

##### Up-Sampled Train Set

```{r}
up_nb_clf <- train_model("naive_bayes", up_train_set)
```

```{r}
plot(up_nb_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
up_nb_tuneGrid <- expand.grid(
  adjust = 1,
  usekernel = FALSE,
  laplace = seq(0, 1, 0.1)
)

up_nb_clf <- train_model("naive_bayes", up_train_set, tuneGrid = up_nb_tuneGrid)
```

```{r}
plot(up_nb_clf)
```

Tuning done.

```{r}
up_nb_metrics <- evaluate_model(up_nb_clf, "NB")
```

#### AdaBoost

##### Original Train Set

```{r}
ab_clf <- train_model("adaboost")
```

```{r}
plot(ab_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
ab_tuneGrid <- expand.grid(
  method = "Real adaboost",
  nIter = seq(150, 500, 50)
)

ab_clf <- train_model("adaboost", tuneGrid = ab_tuneGrid)
```

```{r}
plot(ab_clf)
```

Tuning done.

```{r}
ab_metrics <- evaluate_model(ab_clf, "AB")
```

##### Down-Sampled Train Set

```{r}
down_ab_clf <- train_model("adaboost", down_train_set)
```

```{r}
plot(down_ab_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_ab_tuneGrid <- expand.grid(
  method = "Real adaboost",
  nIter = seq(150, 500, 50)
)

down_ab_clf <- train_model(
  "adaboost",
  down_train_set,
  tuneGrid = down_ab_tuneGrid
)
```

```{r}
plot(down_ab_clf)
```

Tuning done.

```{r}
down_ab_metrics <- evaluate_model(down_ab_clf, "AB")
```

##### Up-Sampled Train Set

```{r}
up_ab_clf <- train_model("adaboost", up_train_set)
```

```{r}
plot(up_ab_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
up_ab_tuneGrid <- expand.grid(
  method = "Real adaboost",
  nIter = seq(150, 500, 50)
)

up_ab_clf <- train_model(
  "adaboost",
  up_train_set,
  tuneGrid = up_ab_tuneGrid
)
```

```{r}
plot(up_ab_clf)
```

Tuning done.

```{r}
up_ab_metrics <- evaluate_model(up_ab_clf, "AB")
```

#### XGBoost (Linear)

##### Original Train Set

```{r}
xgb_lin_clf <- train_model("xgbLinear")
```

```{r}
plot(xgb_lin_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
xgb_lin_tuneGrid <- expand.grid(
  eta = 0.3,
  lambda = 0,
  alpha = 0,
  nrounds = seq(50, 100, 10)
)

xgb_lin_clf <- train_model("xgbLinear", tuneGrid = xgb_lin_tuneGrid)
```

```{r}
plot(xgb_lin_clf)
```

Tuning done.

```{r}
xgb_lin_metrics <- evaluate_model(xgb_lin_clf, "XGB - Linear", "XGB")
```

##### Down-Sampled Train Set

```{r}
down_xgb_lin_clf <- train_model("xgbLinear", down_train_set)
```

```{r}
plot(down_xgb_lin_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_xgb_lin_tuneGrid <- expand.grid(
  eta = 0.3,
  lambda = 0.1,
  alpha = c(0.0001, 0.001, 0.01, 0.1, 0),
  nrounds = seq(50, 200, 10)
)

down_xgb_lin_clf <- train_model(
  "xgbLinear", 
  down_train_set, 
  tuneGrid = down_xgb_lin_tuneGrid
)
```

```{r}
plot(down_xgb_lin_clf)
```

Tuning done.

```{r}
down_xgb_lin_metrics <- evaluate_model(down_xgb_lin_clf, "XGB - Linear", "XGB")
```

##### Up-Sampled Train Set

```{r}
up_xgb_lin_clf <- train_model("xgbLinear", up_train_set)
```

```{r}
plot(up_xgb_lin_clf)
```

No further tuning required.

```{r}
up_xgb_lin_metrics <- evaluate_model(up_xgb_lin_clf, "XGB - Linear", "XGB")
```

#### XGBoost (Tree)

Define a helper function to train XGBoost model with less verbose output.

```{r}
train_xgb_tree <- function(method = "",
                        data = train_set,
                        tuneGrid = NULL,
                        tuneLength = 3) {
  set.seed(42)

  fit <- train(
    result ~ .,
    data = data,
    method = method,
    trControl = fit_control,
    preProcess = c("center", "scale"),
    tuneGrid = tuneGrid,
    tuneLength = tuneLength,
    verbosity = 0
  )

  print(fit)
  
  return(fit)
}
```

##### Original Train Set

```{r}
xgb_tree_clf <- train_xgb_tree("xgbTree")
```

```{r}
plot(xgb_tree_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
xgb_tree_tuneGrid <- expand.grid(
  gamma = 0,
  min_child_weight = 1,
  max_depth = 1,
  eta = 0.4,
  subsample = 1,
  colsample_bytree = seq(0.6, 1.0, 0.1),
  nrounds = seq(100, 200, 10)
)

xgb_tree_clf <- train_xgb_tree("xgbTree", tuneGrid = xgb_tree_tuneGrid)
```

```{r}
plot(xgb_tree_clf)
```

Tuning done.

```{r}
xgb_tree_metrics <- evaluate_model(xgb_tree_clf, "XGB - Tree", "XGB")
```

##### Down-Sampled Train Set

```{r}
down_xgb_tree_clf <- train_xgb_tree("xgbTree", down_train_set)
```

```{r}
plot(down_xgb_tree_clf)
```

No further tuning required.

```{r}
down_xgb_tree_metrics <- evaluate_model(down_xgb_tree_clf, "XGB - Tree", "XGB")
```

##### Up-Sampled Train Set

```{r}
up_xgb_tree_clf <- train_xgb_tree("xgbTree", up_train_set)
```

```{r}
plot(up_xgb_tree_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
up_xgb_tree_tuneGrid <- expand.grid(
  gamma = 0,
  min_child_weight = 1,
  max_depth = 2,
  eta = 0.4,
  subsample = 1,
  colsample_bytree = 0.6,
  nrounds = seq(100, 200, 10)
)

up_xgb_tree_clf <- train_xgb_tree(
  "xgbTree", 
  up_train_set, 
  tuneGrid = up_xgb_tree_tuneGrid
)
```

```{r}
plot(up_xgb_tree_clf)
```

Tuning done.

```{r}
up_xgb_tree_metrics <- evaluate_model(up_xgb_tree_clf, "XGB - Tree", "XGB")
```

#### Neural Network

Define a helper function to train neural network model with less verbose output.

```{r}
train_nn <- function(method = "",
                        data = train_set,
                        tuneGrid = NULL,
                        tuneLength = 3) {
  set.seed(42)

  fit <- train(
    result ~ .,
    data = data,
    method = method,
    trControl = fit_control,
    preProcess = c("center", "scale"),
    tuneGrid = tuneGrid,
    tuneLength = tuneLength,
    trace = FALSE
  )

  print(fit)
  
  return(fit)
}
```

##### Original Train Set

```{r}
nn_clf <- train_nn("nnet")
```

```{r}
plot(nn_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
nn_clf <- train_nn("nnet", tuneLength = 7)
```

```{r}
plot(nn_clf)
```

Tuning done.

```{r}
nn_metrics <- evaluate_model(nn_clf, "NN")
```

##### Down-Sampled Train Set

```{r}
down_nn_clf <- train_nn("nnet", down_train_set)
```

```{r}
plot(down_nn_clf)
```

Perform hyperparameter tuning with `tuneLength`.

```{r}
down_nn_clf <- train_nn("nnet", down_train_set, tuneLength = 7)
```

```{r}
plot(down_nn_clf)
```

Tuning done.

```{r}
down_nn_metrics <- evaluate_model(down_nn_clf, "NN")
```

##### Up-Sampled Train Set

```{r}
up_nn_clf <- train_nn("nnet", up_train_set)
```

```{r}
plot(up_nn_clf)
```

Perform hyperparameter tuning with `tuneLength`.

```{r}
up_nn_clf <- train_nn("nnet", up_train_set, tuneLength = 7)
```

```{r}
plot(up_nn_clf)
```

Tuning done.

```{r}
up_nn_metrics <- evaluate_model(up_nn_clf, "NN")
```

### Evaluation

Define a function to aggregate accuracy from model of same family.

```{r}
aggregate_accuracy <- function(df) {
  df_accuracy <- df %>%
    group_by(Family) %>%
    slice(which.max(Accuracy)) %>%
    arrange(desc(Accuracy)) %>%
    select(-1)

  print(df_accuracy)
  
  plot_accuracy <- df_accuracy %>%
    ggplot(aes(x = reorder(Family, -Accuracy), y = Accuracy, fill = Family)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = Accuracy), vjust=-0.5) +
    ggtitle("Accuracy by Model") +
    xlab("Model") +
    ylim(0, 1) +
    labs(fill = "Model") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
  print(plot_accuracy)
}
```

Define a function to aggregate F1 score from model of same family.

```{r}
aggregate_f1 <- function(df) {
  df_f1 <- df %>%
    group_by(Family) %>%
    slice(which.max(F1)) %>%
    arrange(desc(F1)) %>%
    select(-1)

  print(df_f1)
  
  plot_f1 <- df_f1 %>%
    ggplot(aes(x = reorder(Family, -F1), y = F1, fill = Family)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = F1), vjust=-0.5) +
    ggtitle("F1 Score by Model") +
    xlab("Model") +
    ylab("F1 Score") +
    ylim(0, 1) +
    labs(fill = "Model") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
  print(plot_f1)
}
```

#### Original Train Set

```{r}
df_eval <- rbind(
  dt_metrics,
  rf_metrics,
  svm_lin_metrics,
  svm_poly_metrics,
  svm_rbf_metrics,
  nb_metrics,
  ab_metrics,
  xgb_lin_metrics,
  xgb_tree_metrics,
  nn_metrics
)

df_eval
```

##### By Accuracy

```{r}
aggregate_accuracy(df_eval)
```

##### By F1 Score

```{r}
aggregate_f1(df_eval)
```

#### Down-Sampled Train Set

```{r}
down_df_eval <- rbind(
  down_dt_metrics,
  down_rf_metrics,
  down_svm_lin_metrics,
  down_svm_poly_metrics,
  down_svm_rbf_metrics,
  down_nb_metrics,
  down_ab_metrics,
  down_xgb_lin_metrics,
  down_xgb_tree_metrics,
  down_nn_metrics
)

down_df_eval
```

##### By Accuracy

```{r}
aggregate_accuracy(down_df_eval)
```

##### By F1 Score

```{r}
aggregate_f1(down_df_eval)
```

#### Up-Sampled Train Set

```{r}
up_df_eval <- rbind(
  up_dt_metrics,
  up_rf_metrics,
  up_svm_lin_metrics,
  up_svm_poly_metrics,
  up_svm_rbf_metrics,
  up_nb_metrics,
  up_ab_metrics,
  up_xgb_lin_metrics,
  up_xgb_tree_metrics,
  up_nn_metrics
)

up_df_eval
```

##### By Accuracy

```{r}
aggregate_accuracy(up_df_eval)
```

##### By F1 Score

```{r}
aggregate_f1(up_df_eval)
```
