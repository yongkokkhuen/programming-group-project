---
title: "KNN classification"
author: "Chan Jie Min"
date: '2022-06-07'
output: html_document
---
### Best Result From Previous Study

93% PCC with Decision Tree - [Reference](http://www3.dsi.uminho.pt/pcortez/student.pdf)

### Imports

```{r}
library(dplyr)
library(ggplot2)
library(caret)
```

### Preparation

```{r}
df <- read.csv("../data/student-por_v3.csv", stringsAsFactors = TRUE)
head(df)
```

```{r}
str(df)
```

```{r}
summary(df)
```

Convert ordinal variables into ordered factors.

```{r}
df$famsize <- factor(df$famsize, ordered = TRUE, levels = c("LE3", "GT3"))
df$Medu <- factor(df$Medu, ordered = TRUE, levels = 0:4)
df$Fedu <- factor(df$Fedu, ordered = TRUE, levels = 0:4)
df$traveltime <- factor(df$traveltime, ordered = TRUE, levels = 1:4)
df$studytime <- factor(df$studytime, ordered = TRUE, levels = 1:4)
df$failures <- factor(df$failures, ordered = TRUE, levels = 0:4)
df$famrel <- factor(df$famrel, ordered = TRUE, levels = 1:5)
df$freetime <- factor(df$freetime, ordered = TRUE, levels = 1:5)
df$goout <- factor(df$goout, ordered = TRUE, levels = 1:5)
df$Dalc <- factor(df$Dalc, ordered = TRUE, levels = 1:5)
df$Walc <- factor(df$Walc, ordered = TRUE, levels = 1:5)
df$health <- factor(df$health, ordered = TRUE, levels = 1:5)
```

Drop `G3` column as `G3` will be used for regression.

```{r}
df$G3 <- NULL
```

```{r}
str(df)
```

```{r}
summary(df)
```

### Train-Test Split

```{r}
set.seed(42)

train_index <- createDataPartition(
  df$result,
  p = 0.8,
  list = FALSE,
  times = 1
)

train_set <- df[train_index, ]
test_set <- df[-train_index, ]
```

```{r}
nrow(train_set)
```

```{r}
nrow(test_set)
```

### Subsampling

Check original classes.

```{r}
table(train_set$result)
```

Create sample using down-sampling.

```{r}
set.seed(42)

down_train_set <- downSample(
  x = train_set[, -ncol(train_set)],
  y = train_set$result,
  yname = "result"
)

table(down_train_set$result)
```

Create sample using up-sampling.

```{r}
set.seed(42)

up_train_set <- upSample(
  x = train_set[, -ncol(train_set)],
  y = train_set$result,
  yname = "result"
)

table(up_train_set$result)
```

### Modeling

Define repeated 10-fold cross validation.

```{r}
fit_control <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10
)
```

Define a helper function to train model.

```{r}
train_model <- function(method = "",
                        data = train_set,
                        tuneGrid = NULL,
                        tuneLength = 3) {
  set.seed(42)

  fit <- train(
    result ~ .,
    data = data,
    method = method,
    trControl = fit_control,
    preProcess = c("center", "scale"),
    tuneGrid = tuneGrid,
    tuneLength = tuneLength
  )

  print(fit)
  
  return(fit)
}
```

Define a helper function to evaluate model.

```{r}
evaluate_model <- function(model = NULL, alias = "", family = "") {
  pred <- predict(model, test_set)

  cm <- confusionMatrix(pred, test_set$result, mode = "prec_recall")
  print(cm)

  precision_score <- precision(pred, test_set$result)
  recall_score <- recall(pred, test_set$result)
  f1_score <- F_meas(pred, test_set$result)

  return(data.frame(
    Model = alias,
    Family = ifelse(family == "", alias, family),
    Accuracy = round(cm$overall[["Accuracy"]], 3),
    Precision = round(precision_score, 3),
    Recall = round(recall_score, 3),
    F1 = round(f1_score, 3)
  ))
}
```

#### k- Nearest Neighbour

##### Original Train Set

```{r}
knn_clf <- train_model("knn")
```

```{r}
plot(knn_clf)
```

Check for tuning using `tuneGrid`.

```{r}
knn_clf <- train_model("knn", tuneGrid = expand.grid(k = c(3, 5, 7, 11) ))
```

```{r}
plot(knn_clf)
```
No further tuning necessary. 

```{r}
knn_metrics <- evaluate_model(knn_clf, "knn")
```

##### Down-Sampled Train Set

```{r}
down_knn_clf <- train_model("knn", down_train_set)
```

```{r}
plot(down_knn_clf)
```

Perform hyperparameter tuning using `tuneGrid`.

```{r}
down_knn_clf <- train_model("knn", down_train_set, tuneGrid = expand.grid(k = c(9, 11, 13,15) ))
```

```{r}
plot(down_knn_clf)
```

No further tuning required.

```{r}
down_knn_metrics <- evaluate_model(down_knn_clf, "knn")
```

##### Up-Sampled Train Set

```{r}
up_knn_clf <- train_model("knn", up_train_set)
```

```{r}
plot(up_knn_clf)
```

Perform hyperparameter tuning using `tuneLength`.

```{r}
up_knn_clf <- train_model("knn", up_train_set, tuneGrid = expand.grid(k = c(1,3,5) ))
```

```{r}
plot(up_knn_clf)
```

Tuning done.

```{r}
up_knn_metrics <- evaluate_model(up_knn_clf, "knn")
```
